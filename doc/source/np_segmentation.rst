.. ---------------------------------------------------------------------------
.. Copyright 2016-2018 Intel Corporation
..
.. Licensed under the Apache License, Version 2.0 (the "License");
.. you may not use this file except in compliance with the License.
.. You may obtain a copy of the License at
..
..      http://www.apache.org/licenses/LICENSE-2.0
..
.. Unless required by applicable law or agreed to in writing, software
.. distributed under the License is distributed on an "AS IS" BASIS,
.. WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
.. See the License for the specific language governing permissions and
.. limitations under the License.
.. ---------------------------------------------------------------------------

Noun Phrase Semantic Segmentation
###################################

Overview
========
Noun-Phrase (NP) is a phrase which has a noun (or pronoun) as its head and zero of more dependent modifiers.
Noun-Phrase is the most frequently occurring phrase type and its inner segmentation is critical for understanding the
semantics of the Noun-Phrase.
The most basic division of the semantic segmentation is to two classes:

1. Descriptive Structure - a structure where all dependent modifiers are not changing the semantic meaning of the Head.
2. Collocation Structure - a sequence of words or term that co-occur and change the semantic meaning of the Head.

For example:

- ``fresh hot dog`` - hot dog is a collocation, and changes the head (``dog``) semantic meaning.
- ``fresh hot pizza`` - fresh and hot are descriptions for the pizza.

This model is the first step in the Semantic Segmentation algorithm - the MLP classifier.
The Semantic Segmentation algorithm takes the dependency relations between the Noun-Phrase words, and the MLP classifier inference as the
input - and build a semantic hierarchy that represents the semantic meaning.
The Semantic Segmentation algorithm eventually create a tree where each tier represent a semantic meaning -> if a sequence of words is a
collocation then a collocation tier is created, else the elements are broken down and each one is mapped
to different tier in the tree.

This model trains MLP classifier and inference from such classifier in order to conclude the correct segmentation
for the given NP.

for the examples above the classifier will output 1 (==Collocation) for ``hot dog`` and output 0 (== not collocation)
for ``hot pizza``.


Requirements
=============
- **nltk** (for data.py - used for Wordnet, SnowballStemmer)
- **palmettopy** (for data.py - used for Palmetto PMI scores)
- **requests** (for data.py - used for Wikidata)
- **gensim** (for data.py - used for Word2Vec utilities)
- **tqdm** (for data.py)
- **numpy**

Files
=========
- **data.py**: Prepare string data for both ``train.py`` and ``inference.py`` using pre-trained word embedding, PMI score, Wordnet and wikidata.
- **feature_extraction.py**: contains the feature extraction services
- **train.py**: train the MLP classifier.
- **model.py**: contains the MLP classifier model.
- **inference.py**: load the trained model and inference the input data by the model.

Dataset
=========
The expected dataset is a CSV file with 2 columns.
The first column contains the Noun-Phrase string (a Noun-Phrase containing 2 words),
and the second column contains the correct label (if the 2 word Noun-Phrase is a collocation - the label is 1, else 0)

Attached to this project are examples:

- ``raw_data.csv`` - the dataset before prepare_data.py
- ``prepared_data.csv`` - the output of prepare_data.py

Both of these files are accessible in the following link:

https://s3-us-west-1.amazonaws.com/nervana-modelzoo/np_semantic_segmentation/data.zip


Running Modalities
==================

Pre-processing the data
------------------------

Within the file ``data.py`` a feature vector is extracted from each Noun-Phrase string:

* Word2Vec word embedding (300 size vector for each word in the Noun-Phrase) .
    * Pre-trained Google News Word2vec model can download at https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing
* Cosine distance between 2 words in the Noun-Phrase.
* PMI score (NPMI and UCI scores).
* A binary features whether the Noun-Phrase has existing entity in Wikidata.
* A binary features whether the Noun-Phrase has existing entity in WordNet.

.. code:: python

    python data.py --data datasets/raw_data.csv --output datasets/prepared_data.csv --w2v_path <path_to_w2v>/GoogleNews-vectors-negative300.bin.gz

Training
---------
The file train.py will train the MLP classifier and evaluate it.

After training is done, the model is saved automatically as ``<model_name>.prm``

.. code:: python

    python train.py --data datasets/prepared_data.csv --model datasets/np_semantic_segmentation

Inference
---------
In order to run inference you need to have pre-trained ``<model_name>.prm`` file and data CSV file
that was generated by ``prepare_data.py``.
The result of ``inference.py`` is a CSV file, each row contains the model's inference in respect to
the input data.

.. code:: python

    python inference.py --model datasets/np_semantic_segmentation.prm --data datasets/prepared_data.csv --output datasets/inference_data.csv --print_stats True
